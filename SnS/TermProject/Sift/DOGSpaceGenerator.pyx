# cython: profile=True

# Inside the package we can directly use module name,
# while we must use Sift.`modulename` outside
# # FIXME: (what's wrong with test.py inside this package?)
# from ImagePreprocessing cimport gaussian_blur, decimation, DTYPE_t
from ImagePreprocessing import DTYPE
from ImagePreprocessing cimport decimation
from FeatureDescription cimport *
from Defaults import INTERP_NITER, CONTR_THR, STAB_THR, SIGMA, \
    DSAMP_INTVL, OUT_PATH
cimport Math as mt
import numpy as np
cimport numpy as np
cimport cython


@cython.boundscheck(False)
@cython.wraparound(False)
cdef class GaussianOctave:
    """
    The Gaussian octave generated by blurring an image repeatly.

    scales: DTYPE_t[:, :, ::1]
        (`nscas`+3) images (each image is called a 'scale') blurred from scales[0]
        with different Gaussian kernels.
    diff_scales: DTYPE_t[:, :, ::1]
        (`nscas`+2) images (each image is called a 'scale') by doing difference
        between two neighbored images in `scales`.
    nscas: int
        Number of keypoints, which satisfies: number of images in the octave =
        `nscas`+3
    sigma: DTYPE_t
        `sigma` is the basic Gaussian parameter which means the 'bottom' image
        in the 'bottom' octave is blurred from the original image by convoluting
        with G_\{sigma}(x,y).

    """
    # moved to .pxd for debugging
    # cdef:
    #     DTYPE_t[:, :, ::1] scales
    #     readonly DTYPE_t[:, :, ::1] diff_scales
    #     int nscas, nrows, ncols, n_oct
    #     DTYPE_t sigma

    def __init__(self, DTYPE_t[:, ::1] input, int o, int nscas, DTYPE_t sigma):
        cdef int s, r, c
        self.nrows = input.shape[0]
        self.ncols = input.shape[1]
        self.nscas = nscas
        self.n_oct = o
        self.sigma = sigma
        self.diff_scales = np.zeros([nscas + 2, self.nrows, self.ncols], dtype=DTYPE)
        self.scales = np.zeros([nscas + 3, self.nrows, self.ncols], dtype=DTYPE)

        self.scales[0] = input
        for s in range(1, nscas + 3):
            self.scales[s] = gaussian_blur(self.scales[s - 1],
                    (2 ** (2.0 * s / nscas) - 2 ** (2.0 * (s - 1) / nscas)) ** 0.5
                                           * sigma)
            for r in range(0, self.nrows):
                for c in range(0, self.ncols):
                    self.diff_scales[s - 1, r, c] = \
                        self.scales[s, r, c] - self.scales[s - 1, r, c]

        print("Octave initialized. ")

    cdef tuple _find_exact_extremum(self, int s, int r, int c,
                                    int niter=INTERP_NITER):
        cdef:
            DTYPE_t[:, ::1] deriv = np.zeros([3, 1], dtype=DTYPE)
            DTYPE_t[:, ::1] hessian3 = np.zeros([3, 3], dtype=DTYPE)
            DTYPE_t ds = 0, dr = 0, dc = 0
            int i
            int new_s = s, new_r = r, new_c = c
            DTYPE_t value_of_exact_extremum

        i = 0
        while i < niter:
            # calculate the derivative vector:
            deriv[0, 0] = (self.diff_scales[s + 1, r, c] -
                       self.diff_scales[s - 1, r, c]) / 2
            deriv[1, 0] = (self.diff_scales[s, r + 1, c] -
                       self.diff_scales[s, r - 1, c]) / 2
            deriv[2, 0] = (self.diff_scales[s, r, c + 1] -
                       self.diff_scales[s, r, c - 1]) / 2

            # calculate the Hessian matrix (on s, r, c):
            # /ds^2
            hessian3[0, 0] = self.diff_scales[s + 1, r, c] + \
                self.diff_scales[s - 1, r, c] - 2 * self.diff_scales[s, r, c]
            # /dsdr
            hessian3[0, 1] = (self.diff_scales[s + 1, r + 1, c] +
                self.diff_scales[s - 1, r - 1, c] - self.diff_scales[s + 1, r - 1, c]
                - self.diff_scales[s - 1, r + 1, c]) / 4
            hessian3[1, 0] = hessian3[0, 1]
            # /dsdc
            hessian3[0, 2] = (self.diff_scales[s + 1, r, c + 1] +
                self.diff_scales[s - 1, r, c - 1] - self.diff_scales[s + 1, r, c - 1]
                - self.diff_scales[s - 1, r, c + 1]) / 4
            hessian3[2, 0] = hessian3[0, 1]
            # /dr^2
            hessian3[1, 1] = self.diff_scales[s, r + 1, c] + \
                self.diff_scales[s, r - 1, c] - 2 * self.diff_scales[s, r, c]
            # /drdc
            hessian3[1, 2] = (self.diff_scales[s, r + 1, c + 1] +
                self.diff_scales[s, r - 1, c - 1] - self.diff_scales[s, r - 1, c + 1]
                - self.diff_scales[s, r + 1, c - 1]) / 4
            hessian3[2, 1] = hessian3[1, 2]
            # /dc^2
            hessian3[2, 2] = self.diff_scales[s, r, c + 1] + \
                self.diff_scales[s, r, c - 1] - 2 * self.diff_scales[s, r, c]

            if abs(mt.det(hessian3)) > 10 ** (-8):
                [[ds], [dr], [dc]] = -np.dot(mt.inv(hessian3), deriv)
            # if the Hessian is noninvertible, simply let the offset vector to be 0:
            else:
                ds = 0
                dr = 0
                dc = 0

            if ds > 0.5 and s <= self.nscas - 1:
                new_s += 1
            elif ds < -0.5 and s >= 2:
                new_s -= 1
            elif abs(ds) <= 0.5:
                pass
            else:
                return None

            if dr > 0.5 and r <= self.nrows - 3:
                new_r += 1
            elif dr < -0.5 and r >= 2:
                new_r -= 1
            elif abs(dr) <= 0.5:
                pass
            else:
                return None

            if dc > 0.5 and c <= self.ncols - 3:
                new_c += 1
            elif dc < -0.5 and c >= 2:
                new_c -= 1
            elif abs(dc) <= 0.5:
                pass
            else:
                return None

            value_of_exact_extremum = self.diff_scales[s, r, c] + \
                (deriv[0, 0] * ds + deriv[1, 0] * dr + deriv[2, 0] * dc) / 2

            # if (s, r, c) are unchanged:
            if new_s == s and new_r == r and new_c == c:
                break
            # else, update the coordinates and go on
            s = new_s
            r = new_r
            c = new_c
            i += 1

        # If the exact keypoint is still not found when the loop ends,
        # discard the point:
        if i == niter:
            return None

        return s, r, c, ds, dr, dc, value_of_exact_extremum

    cdef bint _is_low_contrast_or_unstable(self, int s, int r, int c,
                DTYPE_t v, DTYPE_t contrast_threshold=CONTR_THR,
                DTYPE_t stability_threshold=STAB_THR):
        """
        For the experiments in the 'SIFT' paper, all extrema with a value of
        |D(sigma, x, y)| less than 0.03 (which means the extrema are unstable
        with low contrast) were discarded, where D(sigma, x, y) is the Taylor
        expansion (up to the quadratic terms) of the scale-space function.

        """
        cdef:
            DTYPE_t[:, ::1] hessian2 = np.zeros((2, 2), dtype=DTYPE)

        if abs(v) < contrast_threshold:
            return True

        hessian2[0, 0] = self.diff_scales[s, r + 1, c] + \
                self.diff_scales[s, r - 1, c] - 2 * self.diff_scales[s, r, c]
        hessian2[1, 1] = self.diff_scales[s, r, c + 1] + \
                self.diff_scales[s, r, c - 1] - 2 * self.diff_scales[s, r, c]
        hessian2[0, 1] = (self.diff_scales[s, r + 1, c + 1] +
                self.diff_scales[s, r - 1, c - 1] - self.diff_scales[s, r - 1, c + 1]
                - self.diff_scales[s, r + 1, c - 1]) / 4
        hessian2[1, 0] = hessian2[0, 1]

        if np.trace(hessian2) ** 2 / mt.det(hessian2) \
                < (stability_threshold + 1) ** 2 / stability_threshold:
            return False

        return True

    cpdef list find_keypoints_in_octave(self):
        cdef:
            list extrema_points = []
            int r, c, s, index = 0
            # Note the symbols ds, dr, dc have different meanings from those in
            # function _find_exact_extremum
            int ds, dr, dc
            DTYPE_t s_offset = 0, r_offset = 0, c_offset = 0, v = 0
            bint is_keypoint = True
            bint is_maximum = True
            bint is_minimum = True
            Location loc
            PointFeature point
            tuple wildcard

        # For each point,
        for s in range(1, self.nscas + 1):
            for r in range(1, self.nrows - 1):
                for c in range(1, self.ncols - 1):
                    # we compare it with its 26 neighbors
                    # (here itself included, so 27 comparisons in all)
                    for ds in range(-1, 2):
                        for dr in range(-1, 2):
                            for dc in range(-1, 2):
                                if self.diff_scales[s, r, c] < \
                                   self.diff_scales[s + ds, r + dr, c + dc]:
                                    is_maximum = False
                                if self.diff_scales[s, r, c] > \
                                   self.diff_scales[s + ds, r + dr, c + dc]:
                                    is_minimum = False
                                is_keypoint = is_minimum or is_maximum
                                 # if the point cannot be a key point
                                if not is_keypoint:
                                    break
                            if not is_keypoint:
                                break
                        if not is_keypoint:
                            break
                    # if the point IS a key point
                    # (which means is_minimum OR is_maximum is True;
                    # say if is_maximum and is_minimum both are True,
                    # then the point must hava SAME value as all its
                    # neighbors, in which case the point is not a key point):
                    if is_keypoint and (is_maximum != is_minimum):
                        wildcard = self._find_exact_extremum(s, r, c)
                        # If the exact extremum was not found:
                        if not wildcard:
                            # print "NONE!!!"
                            continue
                        # If found:
                        (s, r, c, s_offset, r_offset, c_offset, v) = wildcard
                        if not self._is_low_contrast_or_unstable(s, r, c, v):
                            # TODO: more efficient deduplication?
                            loc = Location(self.n_oct, s, r, c)
                            p = PointFeature(loc,
                                             ((r + r_offset) * 2 ** self.n_oct,
                                              (c + c_offset) * 2 ** self.n_oct),
                                             s + s_offset,
                                             self.sigma * (2 ** (s / self.nscas)))
                            if p not in extrema_points:
                                # print str(p)
                                extrema_points.append(p)

                    # RESET!!!
                    is_keypoint = True
                    is_maximum = True
                    is_minimum = True
        return extrema_points


@cython.boundscheck(False)
@cython.wraparound(False)
cdef class GaussianPyramid:
    """ The Gaussian pyramid of an input image. """
    # cdef:
    #     list octaves
    #     int nocts

    def __init__(self, DTYPE_t[:, ::1] input, int nocts, int nscas,
                 DTYPE_t sigma=SIGMA, bint predesample=False,
                 int predesample_intvl=DSAMP_INTVL):
        """
        :param input: input image (with buffer interface)
            Pixel values are normalize to [0, 1]
        :param nocts: number of octaves
        :param nscas: number of scales in each octave - 3
        :param sigma: (default: SIGMA=1.6)
            The 'bottom' image in the 'bottom' octave is blurred from
            The original image `input` by convoluting with G_\{sigma}(x,y).
        :param predesample: (default: False)
            This parameter is to designate whether the input needs to be
            pre-desampled/decimated before the pyramid starts to be constructed.
        :param predesample_intvl: (default: DSAMP_INTVL=2)
            This parameter is to designate the pre-desample interval. It will
            only work when `predesample` is set 'True'.

        """
        cdef:
            GaussianOctave octave
            int o
            DTYPE_t[:, ::1] first

        self.nocts = nocts
        self.nscas = nscas
        self.sigma = sigma
        self.predesample = predesample
        self.predesample_intvl = predesample_intvl
        self.octaves = []

        if predesample is False:
            first = input
        else:
            first = decimation(input, predesample_intvl)

        first = gaussian_blur(first, sigma)

        for o in range(0, nocts):
            octave = GaussianOctave(first, o, nscas, (2 ** o) * sigma)
            self.octaves.append(octave)
            first = decimation(octave.scales[nscas])
        print("Pyramid initialized. ")
        self.features = self._find_features()

    cdef list _find_keypoints(self):
        """
        return the list of keypoints, which are recorded in the form:
        [[o=0, s0, r0, c0], [o=0, s1, r1, c1],...]

        """
        cdef:
            int o
            list kpts = []
        print("Start finding keypoints...")
        for o in range(0, self.nocts):
            kpts.extend(self.octaves[o].find_keypoints_in_octave())
        print("Finish finding keypoints...")
        return kpts

    cdef list _find_features(self):
        """
        return the list of keypoint features.

        """
        cdef:
            list features
            int i, o, s, r, c
            PointFeature feature

        print("Start finding feature descriptors...")

        # find the keypoints
        features = self._find_keypoints()

        # calculate the keypoints' orientation
        features = calc_keypoints_ori(self, features)

        # calculate the keypoints' feature descriptor vector
        for i in range(0, len(features)):
            feature = features[i]
            o = feature.location.octave
            s = feature.location.scale
            r = feature.location.row
            c = feature.location.col
            feature.descriptor = calc_descriptor(
                self.octaves[o].scales[s], r, c,
                feature.ori,
                feature.sigma_oct)
            # print "print in _find_features: ", np.array(feature.descriptor)

        print("Finish finding feature descriptors...")
        return features

    cpdef save_feature_txt(self, filename, path=OUT_PATH, timestamp=True):
        import os, time

        if not path.endswith(os.sep):
            filename = os.sep.join([path, filename])
        else:
            filename = "".join([path, filename])

        if timestamp:
            timenow = int(time.time())
            time_array = time.localtime(timenow)
            time_str = time.strftime("_%Y%m%d_%H%M%S")
            filename += time_str

        filename = os.extsep.join([filename, "txt"])

        if os.path.exists(filename):
            print("File '{0}' exists. Writing cancelled.".format(filename))
            return

        if os.path.exists(path) == False:
            os.makedirs(path)
            print("Path '{0}' doesn't exist. Create it.".format(path))

        f = open(filename, "w")
        f.write("row_coord" + "\t" + "col_coord" + "\t" + "exact_scale" +
                "\t" + "orientation" + "\t" + "descriptor" + "\n")
        for feature in self.features:
            f.write(str(feature.coord[0]) + "\t" +
                    str(feature.coord[1]) + "\t" +
                    str(feature.sigma_oct) + "\t" +
                    str(feature.ori) + "\t" +
                    str(np.array(feature.descriptor)) + "\n")
        f.close()
        print("Features saved in '{0}'.".format(filename))